{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thabang-r13/stock-price-prediction/blob/main/TransformerModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Stock Price Prediction Transformer Model**"
      ],
      "metadata": {
        "id": "vZeJy8YUw0Xp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3oQ7u_fzA_Af"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data\n",
        "df = pd.read_csv('/content/AMZN.csv')"
      ],
      "metadata": {
        "id": "RL9siGb4BN_1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the first five records\n",
        "df.head()"
      ],
      "metadata": {
        "id": "rkiDPx6JvQ1Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting the 'Close' column for analysis\n",
        "closing_price = df['Close']"
      ],
      "metadata": {
        "id": "6YYlhWRABZug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize the data\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "closing_price = scaler.fit_transform(np.array(closing_price).reshape(-1, 1))"
      ],
      "metadata": {
        "id": "V700n6U1BzWN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create sequences for the transformer model\n",
        "def create_sequences(dataset, time_step):\n",
        "    dataX, dataY = [], []\n",
        "    for i in range(len(dataset) - time_step):\n",
        "        a = dataset[i:(i + time_step), 0]\n",
        "        dataX.append(a)\n",
        "        dataY.append(dataset[i + time_step, 0])\n",
        "    return np.array(dataX), np.array(dataY)\n",
        "\n",
        "# Time step for creating input sequences\n",
        "time_step = 100"
      ],
      "metadata": {
        "id": "gr7hOFQoB5s9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Input sequences and corresponding labels\n",
        "X_transformer, y_transformer = create_sequences(closing_price, time_step)"
      ],
      "metadata": {
        "id": "UMpEOpKdB96s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape the data to fit the transformer model\n",
        "X_transformer = X_transformer.reshape(X_transformer.shape[0], X_transformer.shape[1], 1)"
      ],
      "metadata": {
        "id": "SP8w8ADpCGGB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Building\n",
        "\n",
        "# Transformer encoder block for the model\n",
        "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
        "    # Normalization and Attention\n",
        "    x = layers.LayerNormalization(epsilon=1e-6)(inputs)\n",
        "    x = layers.MultiHeadAttention(\n",
        "        key_dim=head_size, num_heads=num_heads, dropout=dropout\n",
        "    )(x, x)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "    res = x + inputs\n",
        "\n",
        "    # Feed Forward Part\n",
        "    x = layers.LayerNormalization(epsilon=1e-6)(res)\n",
        "    x = layers.Conv1D(filters=ff_dim, kernel_size=1, activation=\"relu\")(x)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "    x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n",
        "    return x + res"
      ],
      "metadata": {
        "id": "nuz6M-0uCHQa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main function to build the entire model\n",
        "def build_model(\n",
        "    input_shape,\n",
        "    head_size,\n",
        "    num_heads,\n",
        "    ff_dim,\n",
        "    num_transformer_blocks,\n",
        "    mlp_units,\n",
        "    dropout=0,\n",
        "    mlp_dropout=0,\n",
        "):\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "    x = inputs\n",
        "    for _ in range(num_transformer_blocks):\n",
        "        x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n",
        "\n",
        "    x = layers.GlobalAveragePooling1D(data_format=\"channels_first\")(x)\n",
        "    for dim in mlp_units:\n",
        "        x = layers.Dense(dim, activation=\"relu\")(x)\n",
        "        x = layers.Dropout(mlp_dropout)(x)\n",
        "    outputs = layers.Dense(1, activation=\"linear\")(x)  # Linear activation for regression\n",
        "    return keras.Model(inputs, outputs)"
      ],
      "metadata": {
        "id": "CkTXUM7tCHXD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the input shape from the preprocessed data\n",
        "input_shape = X_transformer.shape[1:]\n",
        "\n",
        "# Model building with specified hyperparameters\n",
        "model = build_model(\n",
        "    input_shape,\n",
        "    head_size=256,\n",
        "    num_heads=4,\n",
        "    ff_dim=4,\n",
        "    num_transformer_blocks=4,\n",
        "    mlp_units=[128],\n",
        "    mlp_dropout=0.4,\n",
        "    dropout=0.25,\n",
        ")"
      ],
      "metadata": {
        "id": "A9O7Jp1RCHYb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Compiling with mean squared error loss and Adam optimizer\n",
        "model.compile(\n",
        "    loss=\"mean_squared_error\",\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
        ")\n",
        "\n",
        "# Display the summary of the model architecture\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "zQL4APRQCHb8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Early stopping to prevent overfitting\n",
        "callbacks = [keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)]\n",
        "\n",
        "# Train the model on the input sequences and labels\n",
        "model.fit(\n",
        "    X_transformer,\n",
        "    y_transformer,\n",
        "    validation_split=0.2,\n",
        "    epochs=5,\n",
        "    batch_size=64,\n",
        "    callbacks=callbacks,\n",
        ")\n"
      ],
      "metadata": {
        "id": "DiHyD4Wqxiy4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Making Predictions**"
      ],
      "metadata": {
        "id": "eDwC9XRDGC5U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate Input Sequence\n",
        "input_sequence = X_transformer[-1]  # Last available sequence in your dataset\n",
        "\n",
        "# Predictions\n",
        "predictions = []\n",
        "for _ in range(30):\n",
        "    # Reshape input_sequence for prediction\n",
        "    input_sequence_reshaped = input_sequence.reshape(1, input_sequence.shape[0], 1)\n",
        "\n",
        "    # Make prediction\n",
        "    prediction = model.predict(input_sequence_reshaped)\n",
        "\n",
        "    # Append prediction to the list\n",
        "    predictions.append(prediction[0, 0])\n",
        "\n",
        "    # Update input_sequence for the next prediction\n",
        "    input_sequence = np.roll(input_sequence, -1)\n",
        "    input_sequence[-1] = prediction[0, 0]\n",
        "\n",
        "# Inverse Transform\n",
        "predictions = np.array(predictions).reshape(-1, 1)\n",
        "predictions = scaler.inverse_transform(predictions)\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(df['Close'], label='Actual Data')\n",
        "plt.plot(np.arange(len(df['Close']), len(df['Close']) + 30), predictions, label='Predicted Data')\n",
        "plt.title('Price Prediction for the Next 30 Days')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Closing Price')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "amCwEnQ6GBFs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Actual vs Predicted Price**"
      ],
      "metadata": {
        "id": "dzLrh-JY29u4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Training\n",
        "callbacks = [keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)]\n",
        "\n",
        "history = model.fit(\n",
        "    X_transformer,\n",
        "    y_transformer,\n",
        "    validation_split=0.2,\n",
        "    epochs=2,\n",
        "    batch_size=64,\n",
        "    callbacks=callbacks,\n",
        ")\n",
        "\n",
        "# Make predictions on the validation set\n",
        "y_pred = model.predict(X_transformer)\n",
        "\n",
        "# Inverse transform the normalized values to get actual closing prices\n",
        "y_actual = scaler.inverse_transform(y_transformer.reshape(-1, 1))\n",
        "y_pred_actual = scaler.inverse_transform(y_pred.reshape(-1, 1))\n",
        "\n",
        "# Create a DataFrame for comparison\n",
        "comparison_df = pd.DataFrame({\n",
        "    'Actual': y_actual.flatten(),\n",
        "    'Predicted': y_pred_actual.flatten()\n",
        "})\n"
      ],
      "metadata": {
        "id": "RaW-5euq1EpC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Making predictions on the validation set\n",
        "y_pred = model.predict(X_transformer)\n",
        "\n",
        "# Inverse transform the normalized values to get actual closing prices\n",
        "y_actual = scaler.inverse_transform(y_transformer.reshape(-1, 1))\n",
        "y_pred_actual = scaler.inverse_transform(y_pred.reshape(-1, 1))\n",
        "\n",
        "# Plotting the Actual vs Predicted closing prices\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(y_actual, label='Actual Closing Price', color='lime')\n",
        "plt.plot(y_pred_actual, label='Predicted Closing Price', color='red')\n",
        "plt.title('Actual vs Predicted Closing Prices')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Closing Price')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EoK3C8Gl1PW3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}